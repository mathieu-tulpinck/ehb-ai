{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "- https://lifewithdata.com/2022/03/13/how-to-remove-highly-correlated-features-from-a-dataset/\n",
    "- https://app.pluralsight.com/player?course=building-regression-models-scikit-learn&author=janani-ravi&name=1616b48f-65fd-4abd-b9fa-7a2560c9d5de&clip=3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notation\n",
    "\n",
    "|General Notation | Description | Python (if applicable) |\n",
    "|---|---|---|\n",
    "| $a$ | scalar ||\n",
    "| $\\mathbf{a}$ | vector ||\n",
    "| $A$ | matrix ||\n",
    "| **Regression** | | | |\n",
    "|  $X$ | training example matrix | `X_train` |   \n",
    "|  $\\mathbf{y}$  | training example  targets | `y_train` |\n",
    "|  $\\mathbf{x}^{(i)}$| Features of $ith$ Training Example | `X[i]` |\n",
    "|  $\\mathbf{x}^{(i)}$, $y^{(i)}$ | $i{th}$ Training Example | `X[i]`, `y[i]`|\n",
    "| m | number of training examples | `m` |\n",
    "| n | number of features in each example | `n` |\n",
    "|  $\\mathbf{w}$  |  parameter: weight, | `w` |\n",
    "| $b$ | parameter: bias | `b` |     \n",
    "| $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ | The result of the model evaluation at $\\mathbf{x}^{(i)}$ parameterized by $\\mathbf{w},b$: $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)}+b$  | `f_wb` | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies and data import\n",
    "\n",
    "You are asked to predict a final grade of the math course based on the information we have about the student. The dataset is provided in the accompanying file 'student-mat.csv'. A full description of the data set can be found in the file 'metadata.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failures     -0.360415\n",
      "age          -0.161579\n",
      "goout        -0.132791\n",
      "traveltime   -0.117142\n",
      "health       -0.061335\n",
      "Dalc         -0.054660\n",
      "Walc         -0.051939\n",
      "freetime      0.011307\n",
      "absences      0.034247\n",
      "famrel        0.051363\n",
      "studytime     0.097820\n",
      "Fedu          0.152457\n",
      "Medu          0.217147\n",
      "G1            0.801468\n",
      "G2            0.904868\n",
      "G3            1.000000\n",
      "Name: G3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Read from csv.\n",
    "mathscores = pd.read_csv('./data/student-mat.csv', sep=';')\n",
    "\n",
    "# Features G1 and G2 are highly correlated to target and are therefore dropped from the dataset. The idea is that the information they contain are very similar and it would be redundant to include them.\n",
    "print(mathscores.corr()['G3'].sort_values())\n",
    "mathscores_without_G1_G2 = mathscores.drop(['G1', 'G2'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Multiple variable linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 57 columns):\n",
      " #   Column             Non-Null Count  Dtype\n",
      "---  ------             --------------  -----\n",
      " 0   age                395 non-null    int64\n",
      " 1   Medu               395 non-null    int64\n",
      " 2   Fedu               395 non-null    int64\n",
      " 3   traveltime         395 non-null    int64\n",
      " 4   studytime          395 non-null    int64\n",
      " 5   failures           395 non-null    int64\n",
      " 6   famrel             395 non-null    int64\n",
      " 7   freetime           395 non-null    int64\n",
      " 8   goout              395 non-null    int64\n",
      " 9   Dalc               395 non-null    int64\n",
      " 10  Walc               395 non-null    int64\n",
      " 11  health             395 non-null    int64\n",
      " 12  absences           395 non-null    int64\n",
      " 13  G3                 395 non-null    int64\n",
      " 14  school_GP          395 non-null    uint8\n",
      " 15  school_MS          395 non-null    uint8\n",
      " 16  sex_F              395 non-null    uint8\n",
      " 17  sex_M              395 non-null    uint8\n",
      " 18  address_R          395 non-null    uint8\n",
      " 19  address_U          395 non-null    uint8\n",
      " 20  famsize_GT3        395 non-null    uint8\n",
      " 21  famsize_LE3        395 non-null    uint8\n",
      " 22  Pstatus_A          395 non-null    uint8\n",
      " 23  Pstatus_T          395 non-null    uint8\n",
      " 24  Mjob_at_home       395 non-null    uint8\n",
      " 25  Mjob_health        395 non-null    uint8\n",
      " 26  Mjob_other         395 non-null    uint8\n",
      " 27  Mjob_services      395 non-null    uint8\n",
      " 28  Mjob_teacher       395 non-null    uint8\n",
      " 29  Fjob_at_home       395 non-null    uint8\n",
      " 30  Fjob_health        395 non-null    uint8\n",
      " 31  Fjob_other         395 non-null    uint8\n",
      " 32  Fjob_services      395 non-null    uint8\n",
      " 33  Fjob_teacher       395 non-null    uint8\n",
      " 34  reason_course      395 non-null    uint8\n",
      " 35  reason_home        395 non-null    uint8\n",
      " 36  reason_other       395 non-null    uint8\n",
      " 37  reason_reputation  395 non-null    uint8\n",
      " 38  guardian_father    395 non-null    uint8\n",
      " 39  guardian_mother    395 non-null    uint8\n",
      " 40  guardian_other     395 non-null    uint8\n",
      " 41  schoolsup_no       395 non-null    uint8\n",
      " 42  schoolsup_yes      395 non-null    uint8\n",
      " 43  famsup_no          395 non-null    uint8\n",
      " 44  famsup_yes         395 non-null    uint8\n",
      " 45  paid_no            395 non-null    uint8\n",
      " 46  paid_yes           395 non-null    uint8\n",
      " 47  activities_no      395 non-null    uint8\n",
      " 48  activities_yes     395 non-null    uint8\n",
      " 49  nursery_no         395 non-null    uint8\n",
      " 50  nursery_yes        395 non-null    uint8\n",
      " 51  higher_no          395 non-null    uint8\n",
      " 52  higher_yes         395 non-null    uint8\n",
      " 53  internet_no        395 non-null    uint8\n",
      " 54  internet_yes       395 non-null    uint8\n",
      " 55  romantic_no        395 non-null    uint8\n",
      " 56  romantic_yes       395 non-null    uint8\n",
      "dtypes: int64(14), uint8(43)\n",
      "memory usage: 59.9 KB\n",
      "X shape: (316, 56), X type:<class 'numpy.ndarray'>)\n",
      "y shape: (316,), y type:<class 'numpy.ndarray'>)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding of categorical features.\n",
    "mathscores_one_hot_encoded = pd.get_dummies(mathscores_without_G1_G2, columns = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic'])\n",
    "\n",
    "X_features = mathscores_one_hot_encoded.columns.to_numpy()\n",
    "\n",
    "# This method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.\n",
    "mathscores_one_hot_encoded[pd.Series(X_features)].info()\n",
    "\n",
    "X = mathscores_one_hot_encoded.drop('G3', axis = 'columns')\n",
    "y = mathscores_one_hot_encoded['G3']\n",
    "\n",
    "# 80% - 20% split for the training and testing sets. 316/395 = 0.8 \n",
    "# Assign train and test sets (in your experiments, you want to do cross-validation).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "print(f\"X shape: {X_train.shape}, X type:{type(X_train)})\")\n",
    "print(f\"y shape: {y_train.shape}, y type:{type(y_train)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    395.000000\n",
      "mean      10.415190\n",
      "std        4.581443\n",
      "min        0.000000\n",
      "25%        8.000000\n",
      "50%       11.000000\n",
      "75%       14.000000\n",
      "max       20.000000\n",
      "Name: G3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Describe target.\n",
    "print(mathscores['G3'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and fit the regression model - scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "linear_model.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [-3.75038887e-01  4.67036278e-01 -1.49821649e-01 -2.62545954e-01\n",
      "  7.57342843e-01 -1.85389079e+00  2.93824421e-01  2.49172802e-01\n",
      " -4.18607188e-01 -1.44788891e-01  4.23637870e-02 -1.46408626e-01\n",
      "  6.63434586e-02 -1.87584511e+11 -1.87584511e+11  3.22825309e+10\n",
      "  3.22825309e+10  1.84327328e+11  1.84327328e+11  1.07290232e+11\n",
      "  1.07290232e+11 -9.99705610e+10 -9.99705610e+10  4.34082201e+11\n",
      "  4.34082201e+11  4.34082201e+11  4.34082201e+11  4.34082201e+11\n",
      " -4.57323125e+11 -4.57323125e+11 -4.57323125e+11 -4.57323125e+11\n",
      " -4.57323125e+11  2.04867492e+12  2.04867492e+12  2.04867492e+12\n",
      "  2.04867492e+12  1.79968445e+12  1.79968445e+12  1.79968445e+12\n",
      " -4.40216355e+10 -4.40216355e+10 -3.06745247e+10 -3.06745247e+10\n",
      " -2.58108013e+11 -2.58108013e+11 -2.94135973e+11 -2.94135973e+11\n",
      " -1.09925554e+11 -1.09925554e+11 -4.06114206e+10 -4.06114206e+10\n",
      "  1.05765105e+12  1.05765105e+12  1.95179512e+12  1.95179512e+12], b = -6093432517983.33\n"
     ]
    }
   ],
   "source": [
    "b = linear_model.intercept_\n",
    "w = linear_model.coef_\n",
    "print(f\"w = {w:}, b = {b:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction using w,b:\n",
      " [12.0859375  10.671875    2.21386719  9.03222656]\n",
      "Target values \n",
      " [12 14  0  9]\n"
     ]
    }
   ],
   "source": [
    "print(f\"prediction using w,b:\\n {(X_train @ w + b)[:4]}\")\n",
    "print(f\"Target values \\n {y_train[:4]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a166168c68f55598b01c42966d36055a72b05dd81029221af08ea37c30386052"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
